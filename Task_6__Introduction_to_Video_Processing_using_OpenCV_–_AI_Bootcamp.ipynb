{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 6: Introduction to Video Processing with OpenCV"
      ],
      "metadata": {
        "id": "L982FdumDCVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Setup and Video Loading"
      ],
      "metadata": {
        "id": "gk9AwRFXDO6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 1**: Load and Display Video\n",
        "*Instruction*: Load a video file (`sample_video.mp4`) and display it frame-by-frame using OpenCV."
      ],
      "metadata": {
        "id": "tG2LLFb4DSrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load the video file\n",
        "video_path = 'sample_video.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if the video file was opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "# Loop through each frame in the video\n",
        "while True:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Break the loop if the video is finished\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow('Video Frame', frame)\n",
        "\n",
        "    # Wait for a key press. If 'q' is pressed, exit.\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "G6YtbgenDSWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e272f4-d388-41d8-922a-8b1515e5f68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not open video.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Convert Frames to Grayscale"
      ],
      "metadata": {
        "id": "03CKwCBtDzRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 2**: Display Grayscale Video Frames\n",
        "\n",
        "*Instruction*: Convert each frame to grayscale before displaying.\n"
      ],
      "metadata": {
        "id": "oh1W_9m5DuzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "\n",
        "# Load the video file\n",
        "video_path = 'path/to/your/video.mp4' # Replace with your video file path\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "while True:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # If no frame is read, break the loop\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert the frame to grayscale\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Display the grayscale frame\n",
        "    cv2.imshow('Grayscale Video', gray_frame)\n",
        "\n",
        "    # Break the loop if the 'q' key is pressed\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "SQTsWR6GDn6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85375ed3-229b-410d-c10e-c0d9fe7e077d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not open video.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3: Save Processed Video"
      ],
      "metadata": {
        "id": "mVV1BgZvEE3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 3**: Save Grayscale Video to File\n",
        "\n",
        "*Instruction*: Save the grayscale video to disk as `output_gray.avi`.\n"
      ],
      "metadata": {
        "id": "opUK7Z7LEIr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def save_grayscale_video(input_path, output_path):\n",
        "    \"\"\"\n",
        "    Saves a grayscale version of a video to disk.\n",
        "\n",
        "    Args:\n",
        "        input_path (str): Path to the input video file.\n",
        "        output_path (str): Path to save the output grayscale video file.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video file.\")\n",
        "        return\n",
        "\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height), isColor=False)\n",
        "\n",
        "    while(True):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        out.write(gray_frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Example Usage\n",
        "input_video_path = \"input.mp4\" # Replace with your input video path\n",
        "output_video_path = \"output_gray.avi\"\n",
        "save_grayscale_video(input_video_path, output_video_path)\n"
      ],
      "metadata": {
        "id": "UW3FMdjQEEl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec6db2a-58b6-42d0-a6f3-f0ca041b237f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not open video file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4: Real-Time Webcam Feed"
      ],
      "metadata": {
        "id": "GNO0DPi3EpgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 4**: Capture and Display Webcam Feed\n",
        "\n",
        "*Instruction*: Access the webcam and display the live video feed. Press `q` to quit."
      ],
      "metadata": {
        "id": "W74DNGaJEtdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Create a VideoCapture object. The argument 0 refers to the default webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Check if webcam opened successfully\n",
        "if not cap.isOpened():\n",
        "  print(\"Error: Could not open webcam\")\n",
        "  exit()\n",
        "\n",
        "# Loop to capture and display frames\n",
        "while True:\n",
        "  # Read a frame from the webcam\n",
        "  ret, frame = cap.read()\n",
        "\n",
        "  # If no frame was read (e.g., webcam closed unexpectedly), break the loop\n",
        "  if not ret:\n",
        "    print(\"Error: Could not read frame\")\n",
        "    break\n",
        "\n",
        "  # Display the frame\n",
        "  cv2.imshow('Webcam Feed', frame)\n",
        "\n",
        "  # Wait for a key press. The argument 1 is the delay in milliseconds.\n",
        "  # If the key is not pressed within this time, it returns -1.\n",
        "  # We check for 'q' key press (ASCII value 113 or 107) to exit\n",
        "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "    break\n",
        "\n",
        "# Release the webcam and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "aM8iWEAXEOmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a46e54-1db2-4121-aa23-78d274dc718c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not open webcam\n",
            "Error: Could not read frame\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 5: Add Live Effects to Webcam Feed"
      ],
      "metadata": {
        "id": "yFxPFagsE9mS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 5**:  Apply Canny Edge Detection in Real-Time\n",
        "\n",
        "*Instruction*: While capturing from webcam, apply Canny edge detection to each frame and display side-by-side.\n"
      ],
      "metadata": {
        "id": "IZwIOzHXFD1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def apply_canny_edge_detection(frame):\n",
        "    # Convert the frame to grayscale\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(blurred, 100, 200)  # Adjust thresholds as needed\n",
        "\n",
        "    return edges\n",
        "\n",
        "def main():\n",
        "    # Open the default webcam\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open webcam.\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        # Read a frame from the webcam\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            print(\"Error: Could not read frame.\")\n",
        "            break\n",
        "\n",
        "        # Apply Canny edge detection\n",
        "        edges = apply_canny_edge_detection(frame)\n",
        "\n",
        "         # Resize the frames for better side-by-side display\n",
        "        frame_resized = cv2.resize(frame, (320, 240))\n",
        "        edges_resized = cv2.cvtColor(cv2.resize(edges, (320, 240)), cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        # Concatenate the original frame and the edge-detected frame horizontally\n",
        "        combined = np.concatenate((frame_resized, edges_resized), axis=1)\n",
        "\n",
        "        # Display the combined frames\n",
        "        cv2.imshow('Original vs Canny Edges', combined)\n",
        "\n",
        "        # Exit the loop when the 'q' key is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Release the webcam and close all windows\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "VpUFTR1JFDWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d07bed-2b50-4174-9e9a-53aab559560e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not open webcam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 6: Color Spaces and Histogram"
      ],
      "metadata": {
        "id": "w-OY1jI5IaIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 6**: Convert Color Spaces and Plot Histogram\n",
        "\n",
        "*Instruction*: Convert the image to grayscale and HSV. Then plot a histogram of grayscale values."
      ],
      "metadata": {
        "id": "xeBCcr3RIi-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('image.jpg') # Replace 'image.jpg' with your image path\n",
        "\n",
        "# Convert to grayscale\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Convert to HSV\n",
        "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Plot histogram of grayscale image\n",
        "plt.hist(gray_image.flatten(), bins=256, range=[0,256], color='gray')\n",
        "plt.title('Grayscale Histogram')\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gSza6VScIakN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "023e2a21-c58b-492b-aa08-aab2481a5a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bd918da034ed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Convert to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgray_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Convert to HSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    }
  ]
}